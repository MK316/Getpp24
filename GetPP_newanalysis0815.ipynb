{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOFAhd4cIM0hIoLXcNypbNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Getpp24/blob/main/GetPP_newanalysis0815.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0815 Data process revisited\n",
        "\n",
        "+ Puncutation error in counting number of sentences and put them as a list\n",
        "+ data to process: 00_textall.csv (text and text-only columns)"
      ],
      "metadata": {
        "id": "vc3c6MortVRx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L5hILlStU0u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'yourfile.csv' with the actual name of your CSV file\n",
        "# You can find the file name from the 'uploaded' dictionary if needed\n",
        "df = pd.read_csv('/content/00_textall.csv', encoding='utf-8')\n",
        "\n",
        "# Display the column names\n",
        "print(\"Column names in the DataFrame:\")\n",
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the data, add space after sentence puncuations. Then save the file as a new one ('01_textall-space.csv')"
      ],
      "metadata": {
        "id": "5RKl-p72u47p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Solution 3: Use the chardet library to detect the file encoding automatically and load the file with the correct encoding."
      ],
      "metadata": {
        "id": "aLgIsfpp0EXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load your CSV file (replace 'yourfile.csv' with the actual file name)\n",
        "df = pd.read_csv('/content/00_textall.csv')\n",
        "\n",
        "# Function to fix spacing after punctuation marks\n",
        "def fix_spacing(text):\n",
        "    # Use regex to add space after periods, exclamation marks, and question marks if there isn't any\n",
        "    corrected_text = re.sub(r'([.!?])([A-Za-z])', r'\\1 \\2', text)\n",
        "    return corrected_text\n",
        "\n",
        "# Ensure that 'text-only' column is treated as string data\n",
        "df['text-only'] = df['text-only'].astype(str)\n",
        "\n",
        "# Apply the spacing correction function to the 'text-only' column and store it in 'text-corrected'\n",
        "df['text-corrected'] = df['text-only'].apply(fix_spacing)\n",
        "\n",
        "# Save the revised DataFrame with the corrected text to a new CSV file\n",
        "df.to_csv('/content/01_textall-space.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# Optional: Download the CSV file to your local machine in Colab\n",
        "from google.colab import files\n",
        "files.download('/content/01_textall-space.csv')\n"
      ],
      "metadata": {
        "id": "ATrKane61I_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Nsent: 'NumSent'"
      ],
      "metadata": {
        "id": "XoxP6IODzDoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/01_textall-space.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "XDZTEtB4zHgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the column names\n",
        "print(\"Column names in the DataFrame:\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "MEUZghEkzMo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NewSentlist' and NumSent' columns\n",
        "\n",
        "+ Then the data is saved as 02_textall-sentlist.csv"
      ],
      "metadata": {
        "id": "8eY4ZkWG2WQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Download the NLTK 'punkt' tokenizer data for sentence splitting\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load your CSV file (replace 'yourfile.csv' with the actual file name)\n",
        "df = pd.read_csv('/content/01_textall-space.csv')\n",
        "\n",
        "# Step 1: Ensure that 'text-corrected' column is treated as string data\n",
        "df['text-corrected'] = df['text-corrected'].astype(str)\n",
        "\n",
        "# Step 2: Split the text in 'text-corrected' into sentences and store in 'NewSentlist'\n",
        "df['NewSentlist'] = df['text-corrected'].apply(sent_tokenize)\n",
        "\n",
        "# Step 3: Count the number of sentences in each list and store in 'NumSent'\n",
        "df['NumSent'] = df['NewSentlist'].apply(len)\n",
        "\n",
        "# Step 4: Save the modified DataFrame to a new CSV file\n",
        "df.to_csv('/content/02_textall-sentlist.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# Optional: Download the file to your local machine in Colab\n",
        "from google.colab import files\n",
        "files.download('/content/02_textall-sentlist.csv')\n"
      ],
      "metadata": {
        "id": "uFD7jR8o2iHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "3_iBW0qa2-Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bepp vs. Getpp list and counts"
      ],
      "metadata": {
        "id": "NXfrO4Wa3HGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions"
      ],
      "metadata": {
        "id": "uxn7nr_83lSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# List of irregular past participles from the 100 most common English verbs\n",
        "irregular_past_participles = [\n",
        "    'been', 'become', 'begun', 'bent', 'bitten', 'blown', 'broken', 'brought', 'built',\n",
        "    'bought', 'caught', 'chosen', 'come', 'cut', 'done', 'drawn', 'driven', 'eaten',\n",
        "    'fallen', 'fed', 'felt', 'fought', 'found', 'flown', 'forgotten', 'forgiven',\n",
        "    'frozen', 'gotten', 'given', 'gone', 'grown', 'hung', 'heard', 'hidden', 'held',\n",
        "    'kept', 'known', 'laid', 'led', 'left', 'lent', 'let', 'lost', 'made', 'meant',\n",
        "    'met', 'paid', 'put', 'read', 'ridden', 'risen', 'run', 'said', 'seen', 'sold',\n",
        "    'sent', 'set', 'shaken', 'shone', 'shot', 'shown', 'shut', 'sung', 'sunk', 'sat',\n",
        "    'slept', 'spoken', 'spent', 'stood', 'stolen', 'stuck', 'struck', 'sworn', 'swum',\n",
        "    'taken', 'taught', 'torn', 'told', 'thought', 'thrown', 'understood', 'woken',\n",
        "    'won', 'written'\n",
        "]\n",
        "\n",
        "# Convert the list of irregular past participles into a regex pattern\n",
        "irregular_past_participles_pattern = r'\\b(?:' + '|'.join(irregular_past_participles) + r')\\b'\n",
        "\n",
        "# Function to identify 'be' + past participle, including irregular verbs\n",
        "def find_be_passive(sentences):\n",
        "    be_passive_pattern = re.compile(\n",
        "        r'\\b(?:is|are|was|were|am|be|been|being|\\'s)\\s+(?:\\w+ed|\\w+en|' + irregular_past_participles_pattern + r')\\b',\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "    return [sentence for sentence in sentences if be_passive_pattern.search(sentence)]\n",
        "\n",
        "# Function to identify 'get' + past participle, including irregular verbs\n",
        "def find_get_passive(sentences):\n",
        "    get_passive_pattern = re.compile(\n",
        "        r'\\bget\\s+(?:\\w+ed|\\w+en|' + irregular_past_participles_pattern + r')\\b',\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "    return [sentence for sentence in sentences if get_passive_pattern.search(sentence)]\n"
      ],
      "metadata": {
        "id": "Miwt2RaU3hk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count bepp and getpp"
      ],
      "metadata": {
        "id": "Uodrrfws3kY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Q3P7zY8B360x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 3\n",
        "\n",
        "# Load the data\n",
        "data = df\n",
        "\n",
        "# Process each list of sentences\n",
        "data['Bepp'] = data['NewSentlist'].apply(lambda x: find_be_passive(eval(x)))\n",
        "data['Getpp'] = data['NewSentlist'].apply(lambda x: find_get_passive(eval(x)))\n",
        "\n",
        "# Count the number of sentences for each passive form\n",
        "data['Nbepp'] = data['Bepp'].apply(len)\n",
        "data['Ngetpp'] = data['Getpp'].apply(len)\n"
      ],
      "metadata": {
        "id": "ZfQCbjnR3rh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 3\n",
        "\n",
        "# Load the data\n",
        "data = df\n",
        "\n",
        "# Process each list of sentences\n",
        "# Assuming 'NewSentlist' already contains lists of strings\n",
        "data['Bepp'] = data['NewSentlist'].apply(find_be_passive)\n",
        "data['Getpp'] = data['NewSentlist'].apply(find_get_passive)\n",
        "\n",
        "# Count the number of sentences for each passive form\n",
        "data['Nbepp'] = data['Bepp'].apply(len)\n",
        "data['Ngetpp'] = data['Getpp'].apply(len)"
      ],
      "metadata": {
        "id": "3ZTaRQRT4U6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "xZJvuE2G4X-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File to save (getpp-results-new.xlsx)"
      ],
      "metadata": {
        "id": "m-YPpsC55OGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Save the DataFrame as an Excel file\n",
        "data.to_excel('/content/getpp-results-new.xlsx', index=False)\n",
        "\n",
        "# Optional: Download the file directly to your local machine (useful in Colab)\n",
        "from google.colab import files\n",
        "files.download('/content/getpp-results-new.xlsx')\n"
      ],
      "metadata": {
        "id": "jRHW-rD14k3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- Data process completed. Move to analysis"
      ],
      "metadata": {
        "id": "26c5X2WF5U_J"
      }
    }
  ]
}