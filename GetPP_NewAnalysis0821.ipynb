{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNLlKHdzyvyh3ksYgWed61y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Getpp24/blob/main/GetPP_NewAnalysis0821.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ± GetPP-newanalysis (0821 9PM)"
      ],
      "metadata": {
        "id": "G5u3q_Kh6mdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Read data '04-datatoprocess-0815.csv'\n",
        "\n",
        "- This data has getpp beppresults\n",
        "- We'll add byphrase counts"
      ],
      "metadata": {
        "id": "mVAyioqu7ZUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('04-datatoprocess-0815.csv', encoding='utf-8')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "j6CfHoV767jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New columns Getpp-by and Bepp-by; NBepp, NGetpp"
      ],
      "metadata": {
        "id": "Omwip8VY-87w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOc2b5li5232"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load your DataFrame (replace 'yourfile.csv' with your actual file)\n",
        "df = pd.read_csv('04-datatoprocess-0815.csv')\n",
        "\n",
        "# Function to collect sentences that have a \"by\" phrase\n",
        "def extract_by_phrase(sentences):\n",
        "    by_sentences = [sentence for sentence in sentences if re.search(r'\\bby\\b', sentence, re.IGNORECASE)]\n",
        "    return by_sentences\n",
        "\n",
        "# Step 1: Ensure the 'Bepp' and 'Getpp' columns are lists of sentences\n",
        "df['Bepp'] = df['Bepp'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
        "df['Getpp'] = df['Getpp'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "# Step 2: Collect sentences with \"by\" phrase from 'Bepp' and 'Getpp' columns\n",
        "df['Bepp-by'] = df['Bepp'].apply(extract_by_phrase)\n",
        "df['Getpp-by'] = df['Getpp'].apply(extract_by_phrase)\n",
        "\n",
        "# Step 3: Count the number of sentences with \"by\" phrase and store in new columns 'NBepp-by' and 'NGetpp-by'\n",
        "df['NBepp-by'] = df['Bepp-by'].apply(len)\n",
        "df['NGetpp-by'] = df['Getpp-by'].apply(len)\n",
        "\n",
        "# Step 4: Save the final DataFrame to an Excel file\n",
        "df.to_excel('/content/05-newresults.xlsx', index=False)\n",
        "\n",
        "# Optional: Download the Excel file to your local machine in Colab\n",
        "from google.colab import files\n",
        "files.download('/content/05-newresults.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "q6a4svCO_dqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive statistics (0815 9PM)"
      ],
      "metadata": {
        "id": "aXnlIaG9ADqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[final data](https://raw.githubusercontent.com/MK316/Getpp24/main/data/resultall0815-light.csv) 0815 9:33PM\n",
        "\n",
        "+ The data has NSent, Getpp, Bepp, Counts of by-phrase and its list."
      ],
      "metadata": {
        "id": "HF270unRBvAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MK316/Getpp24/main/data/resultall0815-light.csv\"\n",
        "\n",
        "# Step 1: Read the dataframe from the provided URL\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Step 2: Sum the values in 'Nbepp' and 'Ngetpp' columns\n",
        "total_nbepp = df['Nbepp'].sum()\n",
        "total_ngetpp = df['Ngetpp'].sum()\n",
        "total_nsent = df['NumSent'].sum()\n",
        "total_active = total_nsent - (total_nbepp + total_ngetpp)\n",
        "total_passive = total_nbepp + total_ngetpp\n",
        "\n",
        "# Display the results\n",
        "print(f\"Total Nbepp: {total_nbepp}\")\n",
        "print(f\"Total Ngetpp: {total_ngetpp}\")\n",
        "print(f\"Total Numsent: {total_nsent}\")\n",
        "print(f\"Total Passives: {total_passive}\")\n",
        "print(f\"Total Actives: {total_active}\")"
      ],
      "metadata": {
        "id": "JWwT5RCvAJD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame that has been loaded already\n",
        "\n",
        "# Group by 'register' and sum 'Nbepp' and 'Ngetpp' for each register\n",
        "summary_by_register = df.groupby('register')[['Nbepp', 'Ngetpp']].sum()\n",
        "\n",
        "# Add a row for the total sums of each column\n",
        "summary_by_register.loc['Total'] = summary_by_register.sum()\n",
        "\n",
        "# Add a new column that shows the row-wise sum (Nbepp + Ngetpp) for each register\n",
        "summary_by_register['RowSum'] = summary_by_register.sum(axis=1)\n",
        "\n",
        "# Display the result\n",
        "print(summary_by_register)\n"
      ],
      "metadata": {
        "id": "IDQf4vXPEprB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pie chart"
      ],
      "metadata": {
        "id": "B27FrK8IDUB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "total_nbepp = df['Nbepp'].sum()\n",
        "total_ngetpp = df['Ngetpp'].sum()\n",
        "total_nsent = df['NumSent'].sum()\n",
        "total_active = total_nsent - (total_nbepp + total_ngetpp)\n",
        "total_passive = total_nbepp + total_ngetpp\n",
        "\n",
        "\n",
        "# Data provided\n",
        "total_sentences = total_nsent\n",
        "be_passive = total_nbepp\n",
        "get_passive = total_ngetpp\n",
        "passive_total = total_passive\n",
        "active = total_active\n",
        "\n",
        "# Data for pie charts\n",
        "# Left Pie Chart: Active vs Passive\n",
        "labels_left = ['Active Voice', 'Passive Voice']\n",
        "sizes_left = [active, passive_total]\n",
        "\n",
        "# Right Pie Chart: Be-Passive vs Get-Passive\n",
        "labels_right = ['Be-Passive', 'Get-Passive']\n",
        "sizes_right = [be_passive, get_passive]\n",
        "\n",
        "# Step 2: Create Pie Charts with 'darkblue' and 'orange' colors\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Function to determine text color based on background\n",
        "def get_text_color(background_color):\n",
        "    # Explicitly check if the color is darkblue\n",
        "    if background_color == 'darkblue' or background_color == (0.0, 0.0, 0.5450980392156862, 1.0):\n",
        "        return 'white'\n",
        "    else:\n",
        "        return 'black'\n",
        "\n",
        "# Left Pie Chart (Active vs Passive)\n",
        "plt.subplot(1, 2, 1)\n",
        "wedges_left, texts_left, autotexts_left = plt.pie(\n",
        "    sizes_left, labels=labels_left, autopct='%1.1f%%', colors=['darkblue', 'orange'], textprops={'fontsize': 14}\n",
        ")\n",
        "for i, autotext in enumerate(autotexts_left):\n",
        "    autotext.set_color(get_text_color(wedges_left[i].get_facecolor()))\n",
        "\n",
        "plt.title('(a) Active vs Passive Voice', fontsize=16)\n",
        "\n",
        "# Right Pie Chart (Be-Passive vs Get-Passive)\n",
        "plt.subplot(1, 2, 2)\n",
        "wedges_right, texts_right, autotexts_right = plt.pie(\n",
        "    sizes_right, labels=labels_right, autopct='%1.1f%%', colors=['darkblue', 'orange'], textprops={'fontsize': 14}\n",
        ")\n",
        "for i, autotext in enumerate(autotexts_right):\n",
        "    autotext.set_color(get_text_color(wedges_right[i].get_facecolor()))\n",
        "\n",
        "plt.title('(b) Be-Passive vs Get-Passive Voice', fontsize=16)\n",
        "\n",
        "# Save the current figure in high resolution\n",
        "plt.savefig('/content/pie_charts_high_res.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Adjust the overall layout and make the pie charts smaller\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QDDS30vlDV4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chi-squared test"
      ],
      "metadata": {
        "id": "g0UC-bf-FZ7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Step 1: Create the contingency table based on the provided data\n",
        "# The table should reflect the actual counts of occurrences, not percentages\n",
        "\n",
        "# The contingency table:\n",
        "#            | Be-passive | Get-passive |\n",
        "# --------------------------------------\n",
        "# Written    |    12690   |    132      |\n",
        "# Spoken     |    9547    |    371      |\n",
        "\n",
        "contingency_table = np.array([[12690, 132], [9547, 371]])\n",
        "\n",
        "# Step 2: Perform the Chi-squared test\n",
        "chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "# Step 3: Output the results\n",
        "print(f\"Chi-squared Statistic: {chi2}\")\n",
        "print(f\"p-value: {p}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected)\n"
      ],
      "metadata": {
        "id": "OfD5z7bzFbL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample DataFrame (replace this with your actual data)\n",
        "data = {'Register': ['Written', 'Written', 'Spoken', 'Spoken'],\n",
        "        'Type of Passive': ['Be-passive', 'Get-passive', 'Be-passive', 'Get-passive'],\n",
        "        'Observed': [12690, 132, 9547, 371]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Create the contingency table (Observed frequencies in a 2x2 matrix)\n",
        "contingency_table = pd.pivot_table(df, values='Observed', index='Register', columns='Type of Passive')\n",
        "\n",
        "# Step 2: Perform chi-square test and get expected frequencies\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Step 3: Convert expected frequencies into a DataFrame with the same structure as contingency_table\n",
        "expected_df = pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns)\n",
        "\n",
        "# Step 4: Calculate residuals and contributions\n",
        "residuals = contingency_table - expected_df  # Raw residuals\n",
        "standardized_residuals = residuals / np.sqrt(expected_df)  # Standardized residuals\n",
        "contributions = (residuals ** 2) / expected_df  # Contribution to chi-square\n",
        "\n",
        "# Step 5: Display the results\n",
        "print(\"Observed Frequencies:\")\n",
        "print(contingency_table)\n",
        "\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "print(expected_df)\n",
        "\n",
        "print(\"\\nRaw Residuals:\")\n",
        "print(residuals)\n",
        "\n",
        "print(\"\\nStandardized Residuals:\")\n",
        "print(standardized_residuals)\n",
        "\n",
        "print(\"\\nContributions to Chi-square:\")\n",
        "print(contributions)\n",
        "\n",
        "# Step 6: Save the results to a CSV file if needed\n",
        "results = pd.DataFrame({\n",
        "    'Observed': contingency_table.stack(),\n",
        "    'Expected': expected_df.stack(),\n",
        "    'Raw Residual': residuals.stack(),\n",
        "    'Standardized Residual': standardized_residuals.stack(),\n",
        "    'Contribution to Chi-square': contributions.stack()\n",
        "})\n",
        "\n",
        "# Save the results to a CSV\n",
        "results.to_csv('/content/chi_square_results_ordered.csv')\n",
        "\n",
        "# Optional: Download the CSV file in Colab\n",
        "from google.colab import files\n",
        "files.download('/content/chi_square_results_ordered.csv')\n"
      ],
      "metadata": {
        "id": "18gp_HvrJiJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Associate plot"
      ],
      "metadata": {
        "id": "IwFdcTf1Ln4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample DataFrame (replace this with your actual data)\n",
        "data = {'Register': ['Written', 'Written', 'Spoken', 'Spoken'],\n",
        "        'Type of Passive': ['Be-passive', 'Get-passive', 'Be-passive', 'Get-passive'],\n",
        "        'Observed': [12690, 132, 9547, 371]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Create the contingency table (Observed frequencies in a 2x2 matrix)\n",
        "contingency_table = pd.pivot_table(df, values='Observed', index='Register', columns='Type of Passive')\n",
        "\n",
        "# Step 2: Perform chi-square test and get expected frequencies\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Step 3: Convert expected frequencies into a DataFrame with the same structure as contingency_table\n",
        "expected_df = pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns)\n",
        "\n",
        "# Step 4: Calculate residuals, standardized residuals, and contributions\n",
        "residuals = contingency_table - expected_df  # Raw residuals\n",
        "standardized_residuals = residuals / np.sqrt(expected_df)  # Standardized residuals\n",
        "contributions = (residuals ** 2) / expected_df  # Contribution to chi-square\n",
        "\n",
        "# Step 5: Prepare data for plotting standardized residuals\n",
        "std_residuals_flat = standardized_residuals.stack().reset_index(name='Standardized Residuals')\n",
        "contributions_flat = contributions.stack().reset_index(name='Contribution to Chi-square')\n",
        "\n",
        "# Step 6: Plot heatmap of standardized residuals\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a heatmap for standardized residuals\n",
        "pivot_std_residuals = standardized_residuals.reset_index().melt(id_vars='Register', var_name='Type of Passive', value_name='Standardized Residuals')\n",
        "pivot_contributions = contributions.reset_index().melt(id_vars='Register', var_name='Type of Passive', value_name='Contribution to Chi-square')\n",
        "\n",
        "# Plot heatmap of standardized residuals\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(standardized_residuals, annot=True, cmap='coolwarm', center=0, linewidths=.5, fmt=\".2f\")\n",
        "plt.title(\"Heatmap of Standardized Residuals\", fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Plot bar plot of contributions to chi-square\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x='Register', y='Contribution to Chi-square', hue='Type of Passive', data=pivot_contributions, ci=None, palette='Blues', edgecolor='black')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Contributions to Chi-square by Register and Passive Type\", fontsize=16)\n",
        "plt.xlabel(\"Register\", fontsize=14)\n",
        "plt.ylabel(\"Contribution to Chi-square\", fontsize=14)\n",
        "plt.legend(title='Type of Passive', loc='upper right')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CXxw32GQLp0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample DataFrame (replace this with your actual data)\n",
        "data = {'Register': ['Written', 'Written', 'Spoken', 'Spoken'],\n",
        "        'Type of Passive': ['Be-passive', 'Get-passive', 'Be-passive', 'Get-passive'],\n",
        "        'Observed': [12690, 132, 9547, 371]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Create the contingency table (Observed frequencies in a 2x2 matrix)\n",
        "contingency_table = pd.pivot_table(df, values='Observed', index='Register', columns='Type of Passive')\n",
        "\n",
        "# Step 2: Perform chi-square test and get expected frequencies\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Step 3: Convert expected frequencies into a DataFrame with the same structure as contingency_table\n",
        "expected_df = pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns)\n",
        "\n",
        "# Step 4: Calculate standardized residuals\n",
        "residuals = contingency_table - expected_df  # Raw residuals\n",
        "standardized_residuals = residuals / np.sqrt(expected_df)  # Standardized residuals\n",
        "\n",
        "# Step 5: Prepare data for plotting\n",
        "std_residuals_flat = standardized_residuals.stack().reset_index(name='Standardized Residuals')\n",
        "\n",
        "# Step 6: Plot the diverging bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a diverging bar plot\n",
        "sns.barplot(x='Standardized Residuals', y='Register', hue='Type of Passive',\n",
        "            data=std_residuals_flat, palette='rainbow', edgecolor='black')\n",
        "\n",
        "# Add labels and title\n",
        "plt.axvline(0, color='black', linewidth=1)  # Add a vertical line at 0\n",
        "plt.title(\"Diverging Bar Plot of Standardized Residuals\", fontsize=16)\n",
        "plt.xlabel(\"Standardized Residuals\", fontsize=14)\n",
        "plt.ylabel(\"Register\", fontsize=14)\n",
        "plt.legend(title='Type of Passive', loc='upper right')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_QQv3umpMbp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample DataFrame (replace this with your actual data)\n",
        "data = {'Register': ['Written', 'Written', 'Spoken', 'Spoken'],\n",
        "        'Type of Passive': ['Be-passive', 'Get-passive', 'Be-passive', 'Get-passive'],\n",
        "        'Observed': [12690, 132, 9547, 371]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Create the contingency table (Observed frequencies in a 2x2 matrix)\n",
        "contingency_table = pd.pivot_table(df, values='Observed', index='Register', columns='Type of Passive')\n",
        "\n",
        "# Step 2: Perform chi-square test and get expected frequencies\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Step 3: Convert expected frequencies into a DataFrame with the same structure as contingency_table\n",
        "expected_df = pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns)\n",
        "\n",
        "# Step 4: Calculate standardized residuals\n",
        "residuals = contingency_table - expected_df  # Raw residuals\n",
        "standardized_residuals = residuals / np.sqrt(expected_df)  # Standardized residuals\n",
        "\n",
        "# Step 5: Prepare data for plotting\n",
        "std_residuals_flat = standardized_residuals.stack().reset_index(name='Standardized Residuals')\n",
        "\n",
        "# Step 6: Plot the diverging bar plot with custom bright and dark colors\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a custom color palette with bright and dark contrast (e.g., yellow and dark blue)\n",
        "custom_palette = ['#FFD700', '#00008B']  # Bright yellow and dark blue\n",
        "\n",
        "# Create a diverging bar plot with the custom palette\n",
        "sns.barplot(x='Standardized Residuals', y='Register', hue='Type of Passive',\n",
        "            data=std_residuals_flat, palette=custom_palette, edgecolor='black')\n",
        "\n",
        "# Add labels and title\n",
        "plt.axvline(0, color='black', linewidth=1)  # Add a vertical line at 0\n",
        "plt.title(\"Diverging Bar Plot of Standardized Residuals\", fontsize=16)\n",
        "plt.xlim(-10,10)\n",
        "plt.xlabel(\"Standardized Residuals\", fontsize=16)\n",
        "plt.ylabel(\"Register\", fontsize=16)\n",
        "\n",
        "# Customize the legend\n",
        "plt.legend(title='Type of Passive', loc='upper right')\n",
        "\n",
        "# Save the current figure in high resolution\n",
        "plt.savefig('/content/diverging_bar.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vbOhn35hNBmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# By-phrase analysis"
      ],
      "metadata": {
        "id": "7m6LwIQQfC__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MK316/Getpp24/main/data/resultall0815-light.csv\"\n",
        "\n",
        "# Step 1: Read the dataframe from the provided URL\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "3X9p5h3JfFqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "oWsUfnA3fXp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataframe is named df and contains 'NBepp-by', 'NGetpp-by', and 'register' columns\n",
        "\n",
        "# Step 1: Create a contingency table with row sums and column sums\n",
        "contingency_table = df.pivot_table(values=['NBepp-by', 'NGetpp-by'], index='register', aggfunc='sum', margins=True, margins_name='Total')\n",
        "\n",
        "# Step 2: Display the contingency table\n",
        "print(contingency_table)\n"
      ],
      "metadata": {
        "id": "-6_QQV0TfuX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert the results to 'by PP omission'"
      ],
      "metadata": {
        "id": "1NusALdHuEHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MK316/Getpp24/main/data/resultall0815-light.csv\"\n",
        "\n",
        "# Step 1: Read the dataframe from the provided URL\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 1) Get the sum of Nbepp and the sum of Ngetpp by 'register'\n",
        "sum_active_passive = df.groupby('register')[['Nbepp', 'Ngetpp']].sum()\n",
        "\n",
        "# 2) Get the sum of NBepp-by and the sum of NGetpp-by by 'register'\n",
        "sum_by_passive = df.groupby('register')[['NBepp-by', 'NGetpp-by']].sum()\n",
        "\n",
        "# 3) Calculate the 'omission frequency' table by subtracting the second table from the first\n",
        "omission_frequency = sum_active_passive - sum_by_passive\n",
        "\n",
        "# Display the results\n",
        "print(\"Sum of Nbepp and Ngetpp by Register:\\n\", sum_active_passive)\n",
        "print(\"Sum of NBepp-by and NGetpp-by by Register:\\n\", sum_by_passive)\n",
        "print(\"Omission Frequency by Register:\\n\", omission_frequency)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1gmZgXN2uD1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## by omission Chi-squared test"
      ],
      "metadata": {
        "id": "W6aDXTQvzwvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "import numpy as np\n",
        "\n",
        "# Creating the contingency table\n",
        "data = {'BePP': [8083, 9965], 'GetPP': [334, 120]}\n",
        "df = pd.DataFrame(data, index=['Spoken', 'Written'])\n",
        "\n",
        "# Perform the chi-squared test\n",
        "chi2, p, dof, expected = chi2_contingency(df)\n",
        "\n",
        "# Calculate the residuals\n",
        "residuals = (df - expected) / np.sqrt(expected)\n",
        "\n",
        "# Calculate contributions to chi-squared statistic\n",
        "contributions = ((df - expected)**2) / expected\n",
        "\n",
        "# Display the results\n",
        "print(\"Contingency Table:\\n\", df)\n",
        "print(\"\\nExpected Frequencies:\\n\", pd.DataFrame(expected, index=['Spoken', 'Written'], columns=['BePP', 'GetPP']))\n",
        "print(\"\\nChi-squared Statistic:\", chi2)\n",
        "print(\"p-value:\", p)\n",
        "print(\"Degrees of Freedom:\", dof)\n",
        "print(\"\\nResiduals:\\n\", residuals)\n",
        "print(\"\\nContributions:\\n\", contributions)\n"
      ],
      "metadata": {
        "id": "O9ycjI23z0Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divergence plot for by omission"
      ],
      "metadata": {
        "id": "w2WeoYGQ0bhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating the contingency table\n",
        "data = {'BePP': [8083, 9965], 'GetPP': [334, 120]}\n",
        "df = pd.DataFrame(data, index=['Spoken', 'Written'])\n",
        "\n",
        "# Perform the chi-squared test\n",
        "chi2, p, dof, expected = chi2_contingency(df)\n",
        "\n",
        "# Calculate the residuals (observed - expected)\n",
        "residuals = (df - expected) / np.sqrt(expected)\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "plot_data = residuals.unstack().reset_index()\n",
        "plot_data.columns = ['Variable', 'Register', 'Residual']\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "colors = {'BePP': 'lightgray', 'GetPP': 'lightblue'}  # Updated colors\n",
        "for key, group in plot_data.groupby('Variable'):\n",
        "    group.plot(ax=ax, kind='bar', x='Register', y='Residual', label=key, color=colors[key])\n",
        "\n",
        "ax.axhline(0, color='black', linewidth=1)\n",
        "ax.set_ylabel('Standardized Residuals')\n",
        "# ax.set_ylim(-9,9)\n",
        "ax.set_title('Divergence Plot with Residuals')\n",
        "ax.set_xticks(range(len(plot_data['Register'].unique())))\n",
        "ax.set_xticklabels(plot_data['Register'].unique(), rotation=0)\n",
        "plt.legend(title='Variable')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PXGXKfn80eYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be pp: spoken vs. written"
      ],
      "metadata": {
        "id": "cavGV0HP7nD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "import numpy as np\n",
        "\n",
        "# Define the data as a dictionary, then create a DataFrame\n",
        "data = {'With': [1464, 2725], 'Without': [8083, 9965]}\n",
        "df = pd.DataFrame(data, index=['Spoken', 'Written'])\n",
        "\n",
        "# Perform the chi-squared test\n",
        "chi2, p, dof, expected = chi2_contingency(df)\n",
        "\n",
        "# Calculate the residuals (observed - expected)\n",
        "residuals = (df - expected) / np.sqrt(expected)\n",
        "\n",
        "# Print the results\n",
        "print(\"Chi-squared Statistic:\", chi2)\n",
        "print(\"p-value:\", p)\n",
        "print(\"Degrees of Freedom:\", dof)\n",
        "print(\"\\nExpected Frequencies:\\n\", pd.DataFrame(expected, index=['Spoken', 'Written'], columns=['With', 'Without']))\n",
        "print(\"\\nResiduals Table:\\n\", residuals)\n",
        "\n",
        "# Optionally, print the original data table for reference\n",
        "print(\"\\nOriginal Data Table:\\n\", df)\n"
      ],
      "metadata": {
        "id": "fr0L-_XE7pwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "import numpy as np\n",
        "\n",
        "# Define the data as a dictionary, then create a DataFrame\n",
        "data = {'With': [1464, 2725], 'Without': [8083, 9965]}\n",
        "df = pd.DataFrame(data, index=['Spoken', 'Written'])\n",
        "\n",
        "# Perform the chi-squared test\n",
        "chi2, p, dof, expected = chi2_contingency(df)\n",
        "\n",
        "# Calculate the residuals (observed - expected)\n",
        "residuals = (df - expected) / np.sqrt(expected)\n",
        "\n",
        "# Determine significant residuals\n",
        "significant = np.abs(residuals) > 2  # Creates a boolean DataFrame\n",
        "\n",
        "# Print the results\n",
        "print(\"Chi-squared Statistic:\", chi2)\n",
        "print(\"p-value:\", p)\n",
        "print(\"Degrees of Freedom:\", dof)\n",
        "print(\"\\nExpected Frequencies:\\n\", pd.DataFrame(expected, index=['Spoken', 'Written'], columns=['With', 'Without']))\n",
        "print(\"\\nResiduals Table:\\n\", residuals)\n",
        "print(\"\\nSignificant Residuals (|Residual| > 2):\\n\", significant)\n",
        "\n",
        "# Optionally, print the original data table for reference\n",
        "print(\"\\nOriginal Data Table:\\n\", df)\n"
      ],
      "metadata": {
        "id": "e0pRcYpG8ies"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chi-squared test for bepp and getpp omission by register"
      ],
      "metadata": {
        "id": "Cg8G13on-P-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "import numpy as np\n",
        "\n",
        "# Data setup\n",
        "data = {\n",
        "    'BePP with by': [1464, 2725],\n",
        "    'BePP without by': [8083, 9965],\n",
        "    'GetPP with by': [37, 12],\n",
        "    'GetPP without by': [334, 120]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data, index=['Spoken', 'Written'])\n",
        "\n",
        "# Perform the chi-squared test\n",
        "chi2, p, dof, expected = chi2_contingency(df)\n",
        "\n",
        "# Calculate the residuals (observed - expected)\n",
        "residuals = (df - expected) / np.sqrt(expected)\n",
        "\n",
        "# Output the results\n",
        "print(\"Chi-squared Statistic:\", chi2)\n",
        "print(\"p-value:\", p)\n",
        "print(\"Degrees of Freedom:\", dof)\n",
        "print(\"\\nExpected Frequencies:\\n\", pd.DataFrame(expected, index=['Spoken', 'Written'], columns=df.columns))\n",
        "print(\"\\nResiduals Table:\\n\", residuals)\n",
        "print(\"\\nOriginal Data Table:\\n\", df)\n"
      ],
      "metadata": {
        "id": "nLYvM1Ex-VPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heatmap"
      ],
      "metadata": {
        "id": "zh9XQadr_CB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Residuals data from your results\n",
        "residuals_data = {\n",
        "    'BePP with by': [-8.493019, 7.469581],\n",
        "    'BePP without by': [2.382783, -2.095649],\n",
        "    'GetPP with by': [3.380724, -2.973335],\n",
        "    'GetPP without by': [9.664041, -8.499491]\n",
        "}\n",
        "residuals_df = pd.DataFrame(residuals_data, index=['Spoken', 'Written'])\n",
        "\n",
        "# Create a heatmap of the residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(residuals_df, annot=True, cmap='coolwarm', center=0, fmt=\".2f\")\n",
        "plt.title('Heatmap of Standardized Residuals')\n",
        "plt.xlabel('Passive Form Conditions')\n",
        "plt.ylabel('Register')\n",
        "# Save the plot to a file\n",
        "plt.savefig('heatmap_of_residuals.png')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rpphu0CA_Dpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continued analysis"
      ],
      "metadata": {
        "id": "_5ZhXaXp0fKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MK316/Getpp24/main/data/resultall0815-light.csv\"\n",
        "\n",
        "# Step 1: Read the dataframe from the provided URL\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Assuming your dataframe is named df and contains 'NBepp', 'NGetpp', 'NBepp-by', 'NGetpp-by', and 'register' columns\n",
        "\n",
        "# Step 1: Group by 'register' and summarize 'NBepp', 'NGetpp', 'NBepp-by', 'NGetpp-by' using the count method\n",
        "count_summary = df.groupby('register')[['Nbepp', 'Ngetpp', 'NBepp-by', 'NGetpp-by']].sum()\n",
        "\n",
        "# Step 2: Display the count summary\n",
        "print(count_summary)\n"
      ],
      "metadata": {
        "id": "wX1gkwRjgvtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bepp = 9547+12690\n",
        "getpp = 371+132\n",
        "BWB = 1464+2725\n",
        "GWB = 37+12\n",
        "BWTB = bepp - BWB\n",
        "GWTB = getpp - GWB\n",
        "\n",
        "print(f\"Be-passive: {bepp}\")\n",
        "print(f\"Get-passive: {getpp}\")\n",
        "print(f\"Be-passive by-phrase: {BWB}\")\n",
        "print(f\"Get-passive by-phrase: {GWB}\")\n",
        "print(f\"Be-passive without-by-phrase: {BWTB}\")\n",
        "print(f\"Get-passive without-by-phrase: {GWTB}\")\n"
      ],
      "metadata": {
        "id": "h-bsu_RvsaEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = 22740\n",
        "4238/t"
      ],
      "metadata": {
        "id": "l2VYB-STxl3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = 503\n",
        "454/t"
      ],
      "metadata": {
        "id": "Gm87-dPJwKTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your dataframe is named df and contains 'NBepp', 'NGetpp', 'NBepp-by', 'NGetpp-by', and 'register' columns\n",
        "\n",
        "# Step 1: Group by 'register' and sum the relevant columns\n",
        "grouped_data = df.groupby('register')[['Nbepp', 'Ngetpp', 'NBepp-by', 'NGetpp-by']].sum()\n",
        "\n",
        "# Step 2: Calculate the percentage of 'by-phrase' occurrences for Be-passive and Get-passive\n",
        "grouped_data['Be-passive by-phrase (%)'] = (grouped_data['NBepp-by'] / grouped_data['Nbepp']) * 100\n",
        "grouped_data['Get-passive by-phrase (%)'] = (grouped_data['NGetpp-by'] / grouped_data['Ngetpp']) * 100\n",
        "\n",
        "# Step 3: Display the result with the calculated percentages\n",
        "print(grouped_data[['Be-passive by-phrase (%)', 'Get-passive by-phrase (%)']])\n"
      ],
      "metadata": {
        "id": "QUmkr8muhdlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chi-squared test"
      ],
      "metadata": {
        "id": "vSM8d_idinn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create contingency tables for Be-passive and Get-passive (by-phrase vs no by-phrase)\n",
        "data = {\n",
        "    'NBepp-by': [1464, 2725],  # by-phrase counts for Be-passive in spoken and written\n",
        "    'NBepp-no-by': [9547 - 1464, 12690 - 2725],  # no by-phrase counts for Be-passive\n",
        "    'NGetpp-by': [37, 12],  # by-phrase counts for Get-passive\n",
        "    'NGetpp-no-by': [371 - 37, 132 - 12]  # no by-phrase counts for Get-passive\n",
        "}\n",
        "df = pd.DataFrame(data, index=['Spoken', 'Written'])\n",
        "\n",
        "# Chi-squared test for Be-passive\n",
        "bepp_table = df[['NBepp-by', 'NBepp-no-by']]\n",
        "chi2_bepp_stat, p_bepp_value, dof_bepp, expected_bepp = chi2_contingency(bepp_table)\n",
        "\n",
        "# Chi-squared test for Get-passive\n",
        "getpp_table = df[['NGetpp-by', 'NGetpp-no-by']]\n",
        "chi2_getpp_stat, p_getpp_value, dof_getpp, expected_getpp = chi2_contingency(getpp_table)\n",
        "\n",
        "# Print results\n",
        "print(f\"Be-passive Chi-squared: {chi2_bepp_stat}, p-value: {p_bepp_value}\")\n",
        "print(f\"Get-passive Chi-squared: {chi2_getpp_stat}, p-value: {p_getpp_value}\")\n"
      ],
      "metadata": {
        "id": "l5_Pila2ipQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Data: manually input values from your results\n",
        "# 'With By-phrase' and 'Without By-phrase' counts for Be-passive and Get-passive\n",
        "data = {'With By-phrase': [2725, 12],  # NBepp-by for Be-passive, NGetpp-by for Get-passive\n",
        "        'Without By-phrase': [12690 - 2725, 132 - 12]}  # NBepp - NBepp-by for Be-passive, NGetpp - NGetpp-by for Get-passive\n",
        "\n",
        "# Create a DataFrame to represent the contingency table\n",
        "contingency_table = pd.DataFrame(data, index=['Be-passive', 'Get-passive'])\n",
        "\n",
        "# Conduct the chi-squared test\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Chi-squared statistic: {chi2_stat}\")\n",
        "print(f\"p-value: {p_value}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(\"Expected frequencies:\")\n",
        "print(expected)\n"
      ],
      "metadata": {
        "id": "kWZ8akmIjZH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot"
      ],
      "metadata": {
        "id": "VpbAfhWMlkOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Create the observed and expected data (manually input values)\n",
        "observed_data = {\n",
        "    'Register': ['Spoken', 'Spoken', 'Written', 'Written'],\n",
        "    'Passive Type': ['Be-passive', 'Get-passive', 'Be-passive', 'Get-passive'],\n",
        "    'With By-phrase': [1464, 37, 2725, 12],\n",
        "    'Without By-phrase': [9547 - 1464, 371 - 37, 12690 - 2725, 132 - 12]\n",
        "}\n",
        "\n",
        "expected_data = {\n",
        "    'Register': ['Spoken', 'Spoken', 'Written', 'Written'],\n",
        "    'Passive Type': ['Be-passive', 'Get-passive', 'Be-passive', 'Get-passive'],\n",
        "    'With By-phrase': [2708.82, 28.18, 2708.82, 28.18],\n",
        "    'Without By-phrase': [9981.18, 103.82, 9981.18, 103.82]\n",
        "}\n",
        "\n",
        "# Convert observed and expected into DataFrames\n",
        "observed_df = pd.DataFrame(observed_data)\n",
        "expected_df = pd.DataFrame(expected_data)\n",
        "\n",
        "# Step 2: Calculate the standardized residuals\n",
        "observed_df['Std_Res_With_By'] = (observed_df['With By-phrase'] - expected_df['With By-phrase']) / np.sqrt(expected_df['With By-phrase'])\n",
        "observed_df['Std_Res_Without_By'] = (observed_df['Without By-phrase'] - expected_df['Without By-phrase']) / np.sqrt(expected_df['Without By-phrase'])\n",
        "\n",
        "# Step 3: Reshape the data for plotting (from wide to long format)\n",
        "df_melted = pd.melt(observed_df, id_vars=['Register', 'Passive Type'],\n",
        "                    value_vars=['Std_Res_With_By', 'Std_Res_Without_By'],\n",
        "                    var_name='By-phrase Status', value_name='Standardized Residual')\n",
        "\n",
        "# Step 4: Plot the diverging bar plot\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a diverging bar plot using Seaborn without error bars\n",
        "palette = ['#FFD700', '#00008B']  # Custom palette for the bars\n",
        "sns.barplot(x='Standardized Residual', y='Register', hue='Passive Type', data=df_melted,\n",
        "            palette=palette, edgecolor=None, ci=None)\n",
        "\n",
        "# Customize the plot\n",
        "plt.axvline(0, color='black', linewidth=1)  # Add a vertical line at 0\n",
        "plt.title(\"Diverging Bar Plot of Standardized Residuals for By-phrase Usage\", fontsize=14)\n",
        "plt.xlabel(\"Standardized Residual\", fontsize=14)\n",
        "plt.xlim(-25,25)\n",
        "plt.ylabel(\"Register\", fontsize=14)\n",
        "plt.legend(title=\"Passive Type\", loc=\"upper right\")\n",
        "\n",
        "# Save the current figure in high resolution\n",
        "plt.savefig('/content/diverging_bar_byphrase.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NX17EJYnllod"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}